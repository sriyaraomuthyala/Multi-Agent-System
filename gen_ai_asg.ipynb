{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3a6b5e-dfab-4fd0-adf1-730f37eef607",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crewai==0.28.8 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (0.28.8)\n",
      "Requirement already satisfied: crewai_tools==0.1.6 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain_community==0.0.29 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: sumy in c:\\users\\sriya\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Collecting pydantic==1.10.10\n",
      "  Downloading pydantic-1.10.10-cp311-cp311-win_amd64.whl.metadata (150 kB)\n",
      "     ---------------------------------------- 0.0/150.0 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/150.0 kB ? eta -:--:--\n",
      "     ----- ------------------------------- 20.5/150.0 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------ ------------------------ 51.2/150.0 kB 327.7 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 143.4/150.0 kB 853.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 150.0/150.0 kB 747.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (8.1.7)\n",
      "Requirement already satisfied: embedchain<0.2.0,>=0.1.98 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.1.113)\n",
      "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.5.2)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.1.13)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.53.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.27.0)\n",
      "INFO: pip is looking at multiple versions of crewai to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested pydantic==1.10.10\n",
      "    crewai 0.28.8 depends on pydantic<3.0.0 and >=2.4.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install crewai==0.28.8 and pydantic==1.10.10 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 sumy pydantic==1.10.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddb5d771-1bd7-4613-b595-ff11c3b3ad30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spider-client\n",
      "  Downloading spider-client-0.0.72.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from spider-client) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests->spider-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests->spider-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests->spider-client) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests->spider-client) (2024.2.2)\n",
      "Building wheels for collected packages: spider-client\n",
      "  Building wheel for spider-client (setup.py): started\n",
      "  Building wheel for spider-client (setup.py): finished with status 'done'\n",
      "  Created wheel for spider-client: filename=spider_client-0.0.72-py3-none-any.whl size=12953 sha256=eaad44178520951c9875ae97f24451cef4ed3411e8a4a66f0eca3067f2f33b53\n",
      "  Stored in directory: c:\\users\\sriya\\appdata\\local\\pip\\cache\\wheels\\d1\\3f\\9d\\4f73e53fd1a852257b66e5b40c7dd94b160a983c7179139ecf\n",
      "Successfully built spider-client\n",
      "Installing collected packages: spider-client\n",
      "Successfully installed spider-client-0.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spider-client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "055ffd27-8a75-4dc7-819f-0953270b7957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vertexai\n",
      "  Downloading vertexai-1.71.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.71.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.25.5)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.9.2)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.15)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.24.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2024.2.2)\n",
      "Downloading vertexai-1.71.1-py3-none-any.whl (7.3 kB)\n",
      "Installing collected packages: vertexai\n",
      "Successfully installed vertexai-1.71.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "!pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e55e56-e9a8-4383-8ee8-44e3710511e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd696c0-5afc-4156-a993-91ad15bce031",
   "metadata": {},
   "source": [
    "Import libraries, APIs and LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50d19445-ae22-4ac0-97b5-29dd58cb16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool, BaseTool,SeleniumScrapingTool\n",
    "from typing import Type , List , Dict , Optional\n",
    "from pydantic.v1 import BaseModel, Field , PrivateAttr\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import re\n",
    "import requests\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d3500af-72d1-41a5-ad31-e25eb7f3733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_AI_API_KEY\")\n",
    "google_search_api_key = os.getenv(\"GOOGLE_SEARCH_API_KEY\")\n",
    "google_search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
    "serper_api_key = os.getenv(\"SERPER_API_KEY\")\n",
    "#open_ai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00559833-7a83-4f40-8960-b6e582245fc5",
   "metadata": {},
   "source": [
    "Initialize the tools and creating few custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed97292e-6a7f-4ec9-9ff8-dedf72a86f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tool = SerperDevTool()\n",
    "os.environ['GEMINI_AI_=\"google/gemini-pro\")\n",
    "scrape_tool = SeleniumScrapingTool()\n",
    "search_tool = SerperDevTool(\n",
    "    search_url=\"https://google.serper.dev/scholar\",\n",
    "    n_results=5,\n",
    "    api_key = serper_api_key\n",
    ")\n",
    "#summarizer_tool = LsaSummarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284b5ff-eb0b-48bc-9b7f-82555ea6be27",
   "metadata": {},
   "source": [
    "Data Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dea58b3-be6a-49b5-8ec6-85c92e118dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalysisInput(BaseModel):\n",
    "    data: str = Field(..., description=\"Structured data as a JSON string for analysis.\")  # Required field\n",
    "\n",
    "class DataAnalysisTool(BaseTool):\n",
    "    name: str = \"Data Analysis Tool\"\n",
    "    description: str = (\n",
    "        \"Analyzes structured data to provide basic insights such as entry count, mean, median, \"\n",
    "        \"and other relevant statistics.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = DataAnalysisInput\n",
    "\n",
    "    def _run(self, data: str) -> str:\n",
    "        try:\n",
    "            structured_data = json.loads(data)\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Invalid data format. Please provide data in JSON format.\"\n",
    "\n",
    "        # Check if the structured data is a list of numbers\n",
    "        if isinstance(structured_data, list) and all(isinstance(i, (int, float)) for i in structured_data):\n",
    "            entry_count = len(structured_data)\n",
    "            mean_value = statistics.mean(structured_data) if entry_count > 0 else None\n",
    "            median_value = statistics.median(structured_data) if entry_count > 0 else None\n",
    "            stdev_value = statistics.stdev(structured_data) if entry_count > 1 else None\n",
    "\n",
    "            result = {\n",
    "                \"entry_count\": entry_count,\n",
    "                \"mean\": mean_value,\n",
    "                \"median\": median_value,\n",
    "                \"standard_deviation\": stdev_value\n",
    "            }\n",
    "            return json.dumps(result)\n",
    "\n",
    "        return \"Unsupported data format or structure. Please provide a list of numeric values.\"\n",
    "\n",
    "data_analysis_tool = DataAnalysisTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c4689-f31a-497f-a2fb-96b80affbe3b",
   "metadata": {},
   "source": [
    "Text Summarization Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14c32b66-618f-4127-80bf-334f38c0b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationInput(BaseModel):\n",
    "    \"\"\"Input schema for TextSummarizationTool.\"\"\"\n",
    "    text: str = Field(..., description=\"The text to be summarized.\")  # Required field\n",
    "\n",
    "class TextSummarizationTool(BaseTool):\n",
    "    name: str = \"Text Summarization Tool\"\n",
    "    description: str = \"Summarizes text into concise key points or a shorter version.\"\n",
    "    args_schema: Type[BaseModel] = SummarizationInput\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"text-davinci-003\",\n",
    "                prompt=f\"Summarize the following text:\\n{text}\",\n",
    "                max_tokens=100,  # Adjust based on desired summary length\n",
    "                temperature=0.3,\n",
    "            )\n",
    "            return response.choices[0].text.strip() if response.choices else \"No summary generated.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error during summarization: {e}\"\n",
    "\n",
    "text_summarization_tool = TextSummarizationTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d7e7b-09cc-4db3-b882-e3cd07f6e51a",
   "metadata": {},
   "source": [
    "Visualization Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a778650-de90-4dbc-8559-e98e6e708f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationInput(BaseModel):\n",
    "    \"\"\"Input schema for VisualizationTool.\"\"\"\n",
    "    data: str = Field(..., description=\"Data to visualize in JSON format.\")\n",
    "    chart_type: str = Field(..., description=\"Type of chart to create (e.g., 'bar', 'line').\")\n",
    "\n",
    "class VisualizationTool(BaseTool):\n",
    "    name: str = \"Visualization Tool\"\n",
    "    description: str = \"Provides visual representations of data trends and proposed use cases.\"\n",
    "    args_schema: Type[BaseModel] = VisualizationInput\n",
    "\n",
    "    def _run(self, data: str, chart_type: str) -> str:\n",
    "        try:\n",
    "            # Parse data\n",
    "            parsed_data = json.loads(data)\n",
    "\n",
    "            # Generate visualizations based on chart_type\n",
    "            if chart_type == 'bar':\n",
    "                plt.bar(parsed_data['labels'], parsed_data['values'])\n",
    "                plt.title('Bar Chart')\n",
    "                plt.xlabel('Labels')\n",
    "                plt.ylabel('Values')\n",
    "            elif chart_type == 'line':\n",
    "                plt.plot(parsed_data['labels'], parsed_data['values'])\n",
    "                plt.title('Line Chart')\n",
    "                plt.xlabel('Labels')\n",
    "                plt.ylabel('Values')\n",
    "            else:\n",
    "                return \"Unsupported chart type. Please choose 'bar' or 'line'.\"\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            plt.savefig(\"visualization.png\")\n",
    "            plt.close()  # Close the plot to free memory\n",
    "            return \"Visualization created and saved as 'visualization.png'.\"\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            return \"Invalid data format. Please provide data in JSON format.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error during visualization: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f59b6094-62e7-466c-9e74-9a5b28b285c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_tool = VisualizationTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ead676-4a49-4fda-b500-14cfbec9d8c9",
   "metadata": {},
   "source": [
    "Bookmark Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2150b3f-ecb5-4d94-ab3c-7871c6194ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookmarkInput(BaseModel):\n",
    "    \"\"\"Input schema for Bookmark Tool.\"\"\"\n",
    "    name: str = Field(..., description=\"A name for the bookmarked resource.\")\n",
    "    url: str = Field(..., description=\"The URL of the dataset or resource to bookmark.\")\n",
    "    description: str = Field(None, description=\"A brief description of the bookmarked resource.\")\n",
    "\n",
    "class RetrieveBookmarksInput(BaseModel):\n",
    "    \"\"\"Input schema for retrieving bookmarks.\"\"\"\n",
    "    keyword: str = Field(None, description=\"Keyword to search within bookmark names and descriptions for easy retrieval.\")\n",
    "\n",
    "class BookmarkTool(BaseTool):\n",
    "    name: str = \"Bookmark Tool\"\n",
    "    description: str = \"Organizes and saves frequently accessed datasets and resources for easy retrieval and sharing with stakeholders.\"\n",
    "    args_schema: Type[BaseModel] = BookmarkInput\n",
    "    \n",
    "    # Define bookmarks as a Pydantic field with a default empty list\n",
    "    bookmarks: List[dict] = Field(default_factory=list, description=\"List of bookmarked resources.\")\n",
    "    \n",
    "    def _run(self, name: str, url: str, description: str = \"\") -> str:\n",
    "        # Add a new bookmark\n",
    "        bookmark = {\"name\": name, \"url\": url, \"description\": description}\n",
    "        self.bookmarks.append(bookmark)\n",
    "        return f\"Bookmark '{name}' has been added successfully.\"\n",
    "    \n",
    "    def retrieve_bookmarks(self, keyword: str = None) -> str:\n",
    "        # Retrieve bookmarks, filtered by keyword if provided\n",
    "        if keyword:\n",
    "            filtered_bookmarks = [b for b in self.bookmarks if keyword.lower() in (b['name'].lower() + b['description'].lower())]\n",
    "            return json.dumps(filtered_bookmarks, indent=2)\n",
    "        else:\n",
    "            return json.dumps(self.bookmarks, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e22ff73-7fe1-4f83-955e-464132eeb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmark_tool = BookmarkTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835498ce-c16f-434f-8c67-4903c50603c3",
   "metadata": {},
   "source": [
    "Documents Assembly Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e56c42f4-6163-46a4-becf-56e3d5408c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentAssemblyInput(BaseModel):\n",
    "    use_cases: List[Dict[str, str]] = Field(..., description=\"List of use cases with title and description.\")\n",
    "    references: List[Dict[str, str]] = Field(..., description=\"List of references with title and URL.\")\n",
    "    format: str = Field(\"md\", description=\"Format of the document to generate ('txt' or 'md').\")\n",
    "\n",
    "class DocumentAssemblyTool(BaseTool):\n",
    "    name: str = \"Document Assembly Tool\"\n",
    "    description: str = \"Combines insights, suggestions, and resources into a structured document.\"\n",
    "    args_schema: Type[BaseModel] = DocumentAssemblyInput\n",
    "\n",
    "    def _run(self, use_cases: List[Dict[str, str]], references: List[Dict[str, str]], format: str) -> str:\n",
    "        # Validate format\n",
    "        if format not in ['txt', 'md']:\n",
    "            return \"Invalid format specified. Please choose 'txt' or 'md'.\"\n",
    "\n",
    "        # Construct the document content\n",
    "        document_content = \"\"\n",
    "        document_content += \"# Proposal Document\\n\\n\"\n",
    "\n",
    "        # Add use cases to the document\n",
    "        document_content += \"## Use Cases\\n\"\n",
    "        for use_case in use_cases:\n",
    "            document_content += f\"### {use_case['title']}\\n\"\n",
    "            document_content += f\"{use_case['description']}\\n\\n\"\n",
    "\n",
    "        # Add references to the document\n",
    "        document_content += \"## References\\n\"\n",
    "        for reference in references:\n",
    "            if format == 'md':\n",
    "                document_content += f\"- [{reference['title']}]({reference['url']})\\n\"\n",
    "            else:\n",
    "                document_content += f\"- {reference['title']}: {reference['url']}\\n\"\n",
    "\n",
    "        # Save the document\n",
    "        file_extension = 'md' if format == 'md' else 'txt'\n",
    "        file_name = f\"proposal_document.{file_extension}\"\n",
    "        with open(file_name, 'w', encoding='utf-8') as file:\n",
    "            file.write(document_content)\n",
    "\n",
    "        return f\"Document '{file_name}' created successfully.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd665787-a8a4-4e14-9c88-d78fd3df95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembly_tool = DocumentAssemblyTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5f6a-7cf9-4e5e-889c-71f8fd22ee8b",
   "metadata": {},
   "source": [
    "Reference Checker Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a4cb38a-3fe7-4ff4-8434-a2bc104134bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceCheckerInput(BaseModel):\n",
    "    references: List[Dict[str, str]] = Field(..., description=\"List of references with title and URL.\")\n",
    "\n",
    "class ReferenceCheckerTool(BaseTool):\n",
    "    name: str = \"Reference Checker Tool\"\n",
    "    description: str = \"Ensures all referenced sources are correctly cited and formatted within the proposal document.\"\n",
    "    args_schema: Type[BaseModel] = ReferenceCheckerInput\n",
    "\n",
    "    def _run(self, references: List[Dict[str, str]]) -> str:\n",
    "        formatted_references = []\n",
    "\n",
    "        for reference in references:\n",
    "            title = reference.get('title', '').strip()\n",
    "            url = reference.get('url', '').strip()\n",
    "\n",
    "            # Basic validation for title and URL\n",
    "            if not title or not url:\n",
    "                return \"Error: Each reference must have a title and a URL.\"\n",
    "\n",
    "            if not self._is_valid_url(url):\n",
    "                return f\"Error: Invalid URL format for reference '{title}'.\"\n",
    "\n",
    "            # Format the reference\n",
    "            formatted_references.append(f\"- [{title}]({url})\")\n",
    "\n",
    "        return \"Formatted References:\\n\" + \"\\n\".join(formatted_references)\n",
    "\n",
    "    def _is_valid_url(self, url: str) -> bool:\n",
    "        # Simple regex for validating a URL\n",
    "        regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://'  # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n",
    "            r'localhost|'  # localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|'  # IPv4\n",
    "            r'\\[?[A-F0-9]*:[A-F0-9:]+\\]?)'  # IPv6\n",
    "            r'(?::\\d+)?'  # optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "        return re.match(regex, url) is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4d4dafc-b3fa-4a3e-a21a-3d0918ae73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_checker_tool = ReferenceCheckerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7d0f8-7720-46d0-bf36-9f954f8917d2",
   "metadata": {},
   "source": [
    "Link Formatter Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2dae7aef-c305-49da-8c39-c69fa1ea1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkFormatterInput(BaseModel):\n",
    "    text: str = Field(..., description=\"Text containing raw URLs to be formatted as clickable Markdown links.\")\n",
    "\n",
    "class LinkFormatterTool(BaseTool):\n",
    "    name: str = \"Link Formatter Tool\"\n",
    "    description: str = \"Identifies raw URLs in the text and formats them as clickable Markdown links.\"\n",
    "    args_schema: Type[BaseModel] = LinkFormatterInput\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        # Regex pattern to find URLs\n",
    "        url_pattern = r'(https?://[^\\s]+)'\n",
    "\n",
    "        # Function to convert URLs to Markdown format [URL](URL)\n",
    "        def format_link(match):\n",
    "            url = match.group(0)\n",
    "            return f\"[{url}]({url})\"\n",
    "\n",
    "        # Substitute raw URLs with formatted Markdown links\n",
    "        formatted_text = re.sub(url_pattern, format_link, text)\n",
    "\n",
    "        return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cdd389c-7b74-4423-bc06-6f5197b25b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_formatter_tool = LinkFormatterTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f8c3d-4e5e-4479-9cc6-557b18587be8",
   "metadata": {},
   "source": [
    "Feedback and Interation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "172dcc76-7cda-4225-ab6c-cdc808f4fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackEntry(BaseModel):\n",
    "    feedback_id: str = Field(..., description=\"Unique identifier for each feedback entry.\")\n",
    "    stakeholder_name: str = Field(..., description=\"Name of the stakeholder providing feedback.\")\n",
    "    comments: str = Field(..., description=\"Feedback comments for the draft proposal.\")\n",
    "    suggestions: Optional[str] = Field(None, description=\"Suggestions for improvement.\")\n",
    "\n",
    "class FeedbackAndIterationInput(BaseModel):\n",
    "    proposal_id: str = Field(..., description=\"ID of the proposal document to gather feedback on.\")\n",
    "    feedback_entries: List[FeedbackEntry] = Field(..., description=\"List of feedback entries provided by stakeholders.\")\n",
    "\n",
    "class FeedbackAndIterationTool(BaseTool):\n",
    "    name: str = \"Feedback and Iteration Tool\"\n",
    "    description: str = (\n",
    "        \"Collects feedback from stakeholders on draft proposals and refines them iteratively. \"\n",
    "        \"Each feedback entry is stored with stakeholder details and comments, allowing the agent \"\n",
    "        \"to update the proposal document based on received input.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = FeedbackAndIterationInput\n",
    "\n",
    "    # Initialize feedback storage (could be a database in production)\n",
    "    feedback_storage: dict = {}\n",
    "\n",
    "    def _run(self, proposal_id: str, feedback_entries: List[FeedbackEntry]) -> str:\n",
    "        # Check if feedback exists for this proposal, if not initialize\n",
    "        if proposal_id not in self.feedback_storage:\n",
    "            self.feedback_storage[proposal_id] = []\n",
    "        \n",
    "        # Add feedback entries to storage\n",
    "        for feedback in feedback_entries:\n",
    "            self.feedback_storage[proposal_id].append(feedback.dict())\n",
    "        \n",
    "        # Summarize feedback process\n",
    "        feedback_count = len(self.feedback_storage[proposal_id])\n",
    "        return f\"Feedback successfully collected for proposal {proposal_id}. Total feedback entries: {feedback_count}.\"\n",
    "\n",
    "    def refine_proposal(self, proposal_text: str, proposal_id: str) -> str:\n",
    "        \"\"\"Refines the proposal based on feedback entries.\"\"\"\n",
    "        if proposal_id not in self.feedback_storage or not self.feedback_storage[proposal_id]:\n",
    "            return \"No feedback available for refinement.\"\n",
    "\n",
    "        # Iterate over feedback entries for this proposal\n",
    "        refined_proposal = proposal_text\n",
    "        refinement_log = []\n",
    "        \n",
    "        for entry in self.feedback_storage[proposal_id]:\n",
    "            comments = entry['comments']\n",
    "            suggestions = entry.get('suggestions')\n",
    "            \n",
    "            # Simple refinement by appending comments and suggestions for this demo\n",
    "            refined_proposal += f\"\\n\\n# Feedback from {entry['stakeholder_name']}\\n\"\n",
    "            refined_proposal += f\"- Comments: {comments}\\n\"\n",
    "            if suggestions:\n",
    "                refined_proposal += f\"- Suggestions: {suggestions}\\n\"\n",
    "            \n",
    "            # Log each refinement step for traceability\n",
    "            refinement_log.append(f\"Refined based on feedback from {entry['stakeholder_name']}\")\n",
    "        \n",
    "        return refined_proposal + \"\\n\\n\" + \"\\n\".join(refinement_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d58b4aa7-509d-4b56-a2c6-5b071b2b9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_iteration_tool = FeedbackAndIterationTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500d4b3-f89d-462c-a343-d978c6b1ac71",
   "metadata": {},
   "source": [
    "Content Validator Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "478b1faa-ca3f-4a2a-9273-36276d407d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentValidatorInput(BaseModel):\n",
    "    document_text: str = Field(..., description=\"Text of the proposal document to validate.\")\n",
    "    required_sections: List[str] = Field(..., description=\"List of required sections to check for completeness.\")\n",
    "\n",
    "class ContentValidatorTool(BaseTool):\n",
    "    name: str = \"Content Validator Tool\"\n",
    "    description: str = (\n",
    "        \"Validates the completeness and accuracy of a compiled proposal. \"\n",
    "        \"Checks for missing sections, broken links, and incomplete references to ensure document quality.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ContentValidatorInput\n",
    "\n",
    "    def _run(self, document_text: str, required_sections: List[str]) -> str:\n",
    "        # Track validation results\n",
    "        validation_report = []\n",
    "\n",
    "        # Check for required sections\n",
    "        missing_sections = [section for section in required_sections if section not in document_text]\n",
    "        if missing_sections:\n",
    "            validation_report.append(f\"Missing sections: {', '.join(missing_sections)}.\")\n",
    "        else:\n",
    "            validation_report.append(\"All required sections are present.\")\n",
    "\n",
    "        # Check for broken links\n",
    "        validation_report.append(self._check_links(document_text))\n",
    "\n",
    "        # Check for incomplete references\n",
    "        validation_report.append(self._check_references(document_text))\n",
    "\n",
    "        return \"\\n\".join(validation_report)\n",
    "\n",
    "    def _check_links(self, text: str) -> str:\n",
    "        \"\"\"Identify and validate URLs in the document.\"\"\"\n",
    "        url_pattern = r'(https?://[^\\s\\)]+)'\n",
    "        urls = re.findall(url_pattern, text)\n",
    "        broken_links = []\n",
    "\n",
    "        for url in urls:\n",
    "            try:\n",
    "                response = requests.head(url, allow_redirects=True, timeout=5)\n",
    "                if response.status_code >= 400:\n",
    "                    broken_links.append(url)\n",
    "            except requests.RequestException:\n",
    "                broken_links.append(url)\n",
    "\n",
    "        if broken_links:\n",
    "            return f\"Broken links detected: {', '.join(broken_links)}.\"\n",
    "        else:\n",
    "            return \"No broken links detected.\"\n",
    "\n",
    "    def _check_references(self, text: str) -> str:\n",
    "        \"\"\"Detect placeholders or missing references in text.\"\"\"\n",
    "        incomplete_ref_pattern = r'\\[.*?TODO.*?\\]'\n",
    "        incomplete_refs = re.findall(incomplete_ref_pattern, text)\n",
    "\n",
    "        if incomplete_refs:\n",
    "            return f\"Incomplete references detected: {', '.join(incomplete_refs)}.\"\n",
    "        else:\n",
    "            return \"No incomplete references detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1a9cb18-4464-47e6-aec9-48e880cb7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_validator_tool = ContentValidatorTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d40fcd-c92b-499f-9f3e-52879201148d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c634f7-21e4-4e13-ad24-c5fd229f96d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb99cbc-696c-4f8a-92aa-f05e6ed88bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f86ff0c-0652-4724-b4a1-bf88426cfe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevTool'>\n",
      "<class 'crewai_tools.tools.selenium_scraping_tool.selenium_scraping_tool.SeleniumScrapingTool'>\n",
      "<class '__main__.TextSummarizationTool'>\n",
      "<class '__main__.DataAnalysisTool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(search_tool))  # Should print: <class 'your_module.MyTool'>\n",
    "print(type(scrape_tool))  # Should print: <class 'crewai_tools.ScrapeWebsiteTool'>\n",
    "print(type(text_summarization_tool))  # Should print: <class 'crewai_tools.TextSummarizationTool'>\n",
    "print(type(data_analysis_tool))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f46ff-4bf3-4067-bb29-a4f5405873b6",
   "metadata": {},
   "source": [
    "**Creating Agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba45de-ae3d-4412-8a4e-456cf8cb91ec",
   "metadata": {},
   "source": [
    "1. Research Agent\n",
    "2. Market Analyst Agent\n",
    "3. Use Case Generation Agent\n",
    "4. Resource Collecton Agent\n",
    "5. Proposal Finalist Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83705560-6186-4f9b-bd0a-605351a67191",
   "metadata": {},
   "source": [
    "Research Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f79dbec1-19d8-4efa-87a0-f703b9c7a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    role = \"Research Agent\",\n",
    "    goal = \"Conduct industry and company-specific research to identify the company's market segment, key offerings, and strategic focus areas\",\n",
    "    backstory = (\"Uses browser tool to search for information about {company_name} \"\n",
    "            \"in the {industry} sector. It focuses on understanding the industry, segmenting the market, \"\n",
    "            \"and identifying the company's key offerings and strategic focus areas (e.g., operations, supply chain, customer experience).\"),\n",
    "    verbose = True,\n",
    "    allow_delegation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c5f51-01d9-4fb4-adcf-8de6b3b93fab",
   "metadata": {},
   "source": [
    "Market Analyst Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "538690ca-2238-4906-94c3-fc2e3e5a16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_analyst_agent = Agent(\n",
    "    role = \"Market Analyst Agent\",\n",
    "    goal = \"To identify key industry trends, standards, and emerging AI/ML opportunities within the target industry, providing insights that help the company leverage AI/ML to optimize operations, improve customer satisfaction, and drive efficiency.\",\n",
    "    backstory =(\"conducting in-depth analysis of the target industry’s market standards and trends, focusing on AI and ML advancements\"\n",
    "                \" This agent explores recent developments, key innovations, and prominent use cases of AI/ML within the industry\"\n",
    "                \" It identifies opportunities where AI, ML, or Generative AI can add value to processes or enhance customer experience\"\n",
    "                \" By evaluating best practices, the Market Analyst Agent aims to recommend industry-relevant AI solutions that align with the company’s strategic objectives, improving both operational efficiency and customer engagement.\"),\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9d1f0-0bc6-4ab0-ba2e-a7f9615464f2",
   "metadata": {},
   "source": [
    "Use Case Generation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e50ad7c7-dac3-45e7-a1af-b7cb670125cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_generation_agent = Agent(\n",
    "    role = \"Use Case Generation Agent\",\n",
    "    goal = \"To analyze industry data and generate actionable use cases that leverage AI/ML technologies, providing organizations with insights into how to implement predictive maintenance, personalized customer support, and other innovative solutions that enhance operational efficiency and customer experience.\",\n",
    "    backstory = (\"The Use Case Generation Agent was created to bridge the gap between complex industry data and practical applications of AI/ML technologies. \"\n",
    "    \"With a deep understanding of various industries, including manufacturing and retail, this agent meticulously examines historical and current data trends, \"\n",
    "    \"identifies potential areas for improvement, and crafts tailored use cases. By employing GPT-based models and rule-based reasoning, the agent generates insightful recommendations, \"\n",
    "    \"empowering organizations to harness the full potential of AI/ML for optimizing operations and enhancing customer engagement. \"\n",
    "    \"Whether it's predicting equipment failures in manufacturing or crafting personalized customer interactions in retail, \"\n",
    "    \"this agent is equipped to deliver valuable use cases that drive innovation.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e138e4b-3f42-41ab-95d8-0067308df70e",
   "metadata": {},
   "source": [
    "Resource Collector Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8281691-5ef7-439d-ae74-8d3cc2ab730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_collector_agent = Agent(\n",
    "    role = \"Resource Collection Agent\",\n",
    "    goal = \"To efficiently gather high-quality datasets and reference materials from sources like Kaggle, GitHub, and Hugging Face, enabling data scientists, analysts, and developers to accelerate their work on machine learning and AI projects.\",\n",
    "    backstory =  (\"The Resource Collection Agent was developed to streamline the often time-consuming process of locating \"\n",
    "    \"relevant datasets and resources for data-driven projects. With access to platforms like Kaggle, GitHub, \"\n",
    "    \"and Hugging Face, this agent specializes in searching and curating datasets and reference materials based \"\n",
    "    \"on specific project needs, such as image datasets for computer vision or text corpora for NLP. By leveraging \"\n",
    "    \"its understanding of each platform’s structure and filtering capabilities, the agent ensures that users receive \"\n",
    "    \"accurate, curated collections of resources, significantly reducing the time needed for project preparation. \"\n",
    "    \"The agent continually updates its knowledge to track newly released datasets and materials, making it a reliable \"\n",
    "    \"guide to the ever-growing world of open-source data and machine learning resources.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb47da1-729f-46a6-b090-4fd028abb5b5",
   "metadata": {},
   "source": [
    "Proposal Finalist Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aec74dee-d439-4c17-8476-d7da2cc81c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_finalist_agent = Agent(\n",
    "    role = \"Proposal Finalist Agent\",\n",
    "    goal = \"Aims to create a cohesive, well-formatted proposal document that integrates suggested use cases, provides accessible resources, and includes a clear list of references to enhance credibility and facilitate seamless sharing with stakeholders.\",\n",
    "    backstory = (\"The Proposal Finalist Agent was developed to assist teams in turning insights and research findings into structured, actionable proposals. \"\n",
    "    \"It organizes extensive data, resources, and references, ensuring clear presentation with clickable links and credible citations. \"\n",
    "    \"This agent compiles essential details into an accessible format, helping teams progress from insights to actionable strategies, \"\n",
    "    \"and providing value to both technical and non-technical stakeholders.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635efcad-170e-46cd-8f9b-8e1a9d64f3f6",
   "metadata": {},
   "source": [
    "**Creating Tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b4b002c-0509-4a95-9028-2fac20b69c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "research = Task(\n",
    "    description=(\n",
    "        \"Conduct an in-depth analysis of {company_name}, \"\n",
    "        \"a company in the {industry} sector \"\n",
    "        \"that recently showed interest in our solutions. \"\n",
    "        \"Utilize all available data sources \"\n",
    "        \"to compile a detailed profile, \"\n",
    "        \"focusing on key decision-makers, recent business \"\n",
    "        \"developments, and potential needs \"\n",
    "        \"that align with our offerings. \"\n",
    "        \"This task is crucial for tailoring \"\n",
    "        \"our engagement strategy effectively.\\n\"\n",
    "        \"Don't make assumptions and \"\n",
    "        \"only use information you absolutely sure about.\"\n",
    "    ),\n",
    "    expected_output=(\"A comprehensive report on {company_name}, \"\n",
    "        \"including company background, \"\n",
    "        \"key personnel, recent milestones, and identified needs. \"\n",
    "        \"Highlight potential areas where \"\n",
    "        \"our solutions can provide value, \"\n",
    "        \"and suggest personalized engagement strategies.\"),\n",
    "    tools = [search_tool, scrape_tool],\n",
    "    #openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    agent = research_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3c0b2bf-acc0-448b-a9cf-376b6a12393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_analysis_task = Task(\n",
    "    description = (\"Analyze industry-specific trends, benchmarks, and advancements in AI and machine learning. Identify emerging opportunities to drive innovation and competitive advantage within the target sector. Provide actionable insights and recommend areas for strategic AI/ML investments and development.\"),\n",
    "    expected_output = (\"Develop a comprehensive market analysis report to uncover key trends, growth opportunities, and potential market gaps. This report should include data-driven insights, visualizations, and actionable recommendations to support strategic business decisions.\"),\n",
    "    tools = [search_tool, scrape_tool, text_summarization_tool, data_analysis_tool],\n",
    "    agent = market_analyst_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3963d5e-981c-4c96-9b72-0798e976140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case_generation_task = Task(\n",
    "    description = (\"Generate use cases by mapping company goals to potential AI/ML solutions.\"),\n",
    "    expected_output = (\"Detailed list of AI/ML use cases relevant to company goals\"\n",
    "        \"Brief impact analysis and feasibility overview for each use case\"\n",
    "        \"Outline of data requirements and success metrics per use case\"),\n",
    "    agent = usecase_generation_agent,\n",
    "    tools = [search_tool , text_summarization_tool , data_analysis_tool , visualization_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddc4be35-a06f-4731-a676-496c9798e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_collection_task = Task (\n",
    "    description = (\"Identify and curate high-quality datasets along with associated reference resources from top data platforms, including Kaggle, GitHub, and HuggingFace.\"),\n",
    "    expected_output = (\"A well-organized document or spreadsheet with dataset names, links, descriptions, and notes on their relevance to the project.\"),\n",
    "    agent = resource_collector_agent,\n",
    "    tools = [search_tool , scrape_tool, text_summarization_tool, bookmark_tool ],\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0838c1e-f716-4fad-93ce-023b79ba9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_finalization_task = Task(\n",
    "    description = (\"Consolidate all components of the final proposal into a single document.\"\n",
    "\"Ensure that all resources referenced within the proposal are presented in a readable format (e.g., properly formatted text, bullet points, etc.)\"\n",
    "\"Include references for suggested use cases to support the proposal's recommendations.\"\n",
    "\"Verify that all resource asset links are functional and clickable, allowing easy access for readers.\"),\n",
    "    expected_output = (\"Final proposal document in .txt or .md format.\"),\n",
    "    agent = proposal_finalist_agent,\n",
    "    tools = [document_assembly_tool, reference_checker_tool, link_formatter_tool, text_summarization_tool, feedback_iteration_tool , content_validator_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff2d74-2b64-498a-b092-ab6dcdedf610",
   "metadata": {},
   "source": [
    "Creating Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b46ff95-7f4e-4eda-a26a-827bde119e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 22:06:08,207 - 34456 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[research_agent , market_analyst_agent , usecase_generation_agent , resource_collector_agent , proposal_finalist_agent ],\n",
    "    tasks=[research, \n",
    "           market_analysis_task,\n",
    "           use_case_generation_task,\n",
    "           resource_collection_task,\n",
    "           proposal_finalization_task],\n",
    "\t\n",
    "    verbose=2,\n",
    "\tmemory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24553c14-988e-4cf0-a2a3-023e991faeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"company_name\":\"AI Planet\",\n",
    "          \"lead_name\":\"AI Planet\",\n",
    "          \"industry\" : \"Online Learning Platform\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b7c228f-72c5-448e-bd77-1fa580b33331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Research Agent\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct an in-depth analysis of AI Planet, a company in the Online Learning Platform sector that recently showed interest in our solutions. Utilize all available data sources to compile a detailed profile, focusing on key decision-makers, recent business developments, and potential needs that align with our offerings. This task is crucial for tailoring our engagement strategy effectively.\n",
      "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m crew\u001b[38;5;241m.\u001b[39mkickoff(inputs \u001b[38;5;241m=\u001b[39m inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\crew.py:252\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[1;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sequential_process()\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[0;32m    254\u001b[0m     result, manager_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\crew.py:293\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_log_file:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_handler\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m    290\u001b[0m         agent\u001b[38;5;241m=\u001b[39mrole, task\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mdescription, status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[1;32m--> 293\u001b[0m output \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mexecute(context\u001b[38;5;241m=\u001b[39mtask_output)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39masync_execution:\n\u001b[0;32m    295\u001b[0m     task_output \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\task.py:173\u001b[0m, in \u001b[0;36mTask.execute\u001b[1;34m(self, agent, context, tools)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m    174\u001b[0m         task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    175\u001b[0m         agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[0;32m    176\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    177\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\task.py:182\u001b[0m, in \u001b[0;36mTask._execute\u001b[1;34m(self, agent, task, context, tools)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, task, context, tools):\n\u001b[1;32m--> 182\u001b[0m     result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mexecute_task(\n\u001b[0;32m    183\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    184\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    185\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     exported_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[0;32m    191\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m    192\u001b[0m         exported_output\u001b[38;5;241m=\u001b[39mexported_output,\n\u001b[0;32m    193\u001b[0m         raw_output\u001b[38;5;241m=\u001b[39mresult,\n\u001b[0;32m    194\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\agent.py:207\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[1;34m(self, task, context, tools)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39mmemory:\n\u001b[0;32m    202\u001b[0m     contextual_memory \u001b[38;5;241m=\u001b[39m ContextualMemory(\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_short_term_memory,\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_long_term_memory,\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_entity_memory,\n\u001b[0;32m    206\u001b[0m     )\n\u001b[1;32m--> 207\u001b[0m     memory \u001b[38;5;241m=\u001b[39m contextual_memory\u001b[38;5;241m.\u001b[39mbuild_context_for_task(task, context)\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m memory\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m         task_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi18n\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(memory\u001b[38;5;241m=\u001b[39mmemory)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\memory\\contextual\\contextual_memory.py:22\u001b[0m, in \u001b[0;36mContextualMemory.build_context_for_task\u001b[1;34m(self, task, context)\u001b[0m\n\u001b[0;32m     20\u001b[0m context \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_ltm_context(task\u001b[38;5;241m.\u001b[39mdescription))\n\u001b[1;32m---> 22\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_stm_context(query))\n\u001b[0;32m     23\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_entity_context(query))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, context))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\memory\\contextual\\contextual_memory.py:31\u001b[0m, in \u001b[0;36mContextualMemory._fetch_stm_context\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_stm_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, query) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Fetches recent relevant insights from STM related to the task's description and expected_output,\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    formatted as bullet points.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     stm_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstm\u001b[38;5;241m.\u001b[39msearch(query)\n\u001b[0;32m     32\u001b[0m     formatted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m stm_results])\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecent Insights:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mformatted_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stm_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\memory\\short_term\\short_term_memory.py:23\u001b[0m, in \u001b[0;36mShortTermMemory.search\u001b[1;34m(self, query, score_threshold)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, score_threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.35\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39msearch(query\u001b[38;5;241m=\u001b[39mquery, score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\crewai\\memory\\storage\\rag_storage.py:90\u001b[0m, in \u001b[0;36mRAGStorage.search\u001b[1;34m(self, query, limit, filter, score_threshold)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress_logging():\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m         results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39msearch(query, limit, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m)\n\u001b[0;32m     89\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m\n\u001b[1;32m---> 90\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39msearch(query, limit)\n\u001b[0;32m     91\u001b[0m         )\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidDimensionException:\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\embedchain\\embedchain.py:653\u001b[0m, in \u001b[0;36mEmbedChain.search\u001b[1;34m(self, query, num_documents, where, raw_filter, namespace)\u001b[0m\n\u001b[0;32m    642\u001b[0m filter_criteria \u001b[38;5;241m=\u001b[39m raw_filter \u001b[38;5;28;01mif\u001b[39;00m raw_filter \u001b[38;5;28;01melse\u001b[39;00m where\n\u001b[0;32m    644\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_results\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_documents,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    650\u001b[0m     filter_type: filter_criteria,\n\u001b[0;32m    651\u001b[0m }\n\u001b[1;32m--> 653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;241m1\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\embedchain\\vectordb\\chroma.py:220\u001b[0m, in \u001b[0;36mChromaDB.query\u001b[1;34m(self, input_query, n_results, where, raw_filter, citations, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     where_clause \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_where_clause(where)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    221\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    222\u001b[0m             input_query,\n\u001b[0;32m    223\u001b[0m         ],\n\u001b[0;32m    224\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[0;32m    225\u001b[0m         where\u001b[38;5;241m=\u001b[39mwhere_clause,\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidDimensionException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDimensionException(\n\u001b[0;32m    229\u001b[0m         e\u001b[38;5;241m.\u001b[39mmessage()\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. This is commonly a side-effect when an embedding function, different from the one used to add the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m embeddings, is used to retrieve an embedding from the database.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:327\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_query_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_texts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         valid_query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mvalid_query_texts)\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m         valid_query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mvalid_query_images)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:633\u001b[0m, in \u001b[0;36mCollection._embed\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.trychroma.com/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    632\u001b[0m     )\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\types.py:193\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[1;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\utils\\embedding_functions.py:188\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v1:\n\u001b[1;32m--> 188\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deployment_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name\n\u001b[0;32m    190\u001b[0m     )\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    126\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    127\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    128\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    129\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    130\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    131\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    132\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    133\u001b[0m     ),\n\u001b[0;32m    134\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    135\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1276\u001b[0m     )\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    955\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    956\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    957\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    958\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    959\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    960\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1044\u001b[0m         input_options,\n\u001b[0;32m   1045\u001b[0m         cast_to,\n\u001b[0;32m   1046\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1047\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1048\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1049\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1050\u001b[0m     )\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1093\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1094\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1095\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1096\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1097\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1098\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1044\u001b[0m         input_options,\n\u001b[0;32m   1045\u001b[0m         cast_to,\n\u001b[0;32m   1046\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1047\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1048\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1049\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1050\u001b[0m     )\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1093\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1094\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1095\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1096\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1097\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1098\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1067\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "results = crew.kickoff(inputs = inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbe8c3-1fef-4a2e-814f-3420f2ba9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36de865-073c-4fe3-952f-803b1d1fb3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
